[
    {
      "question": "Which of the following statements describe a valid test objective?",
      "selectCount": 1,
      "options": [
        { "text": "a) To prove that there are no unfixed defects in the system under test", "correct": false },
        { "text": "b) To prove that there will be no failures after the implementation of the system into production", "correct": false },
        { "text": "c) To reduce the risk level of the test object and to build confidence in the quality level", "correct": true },
        { "text": "d) To verify that there are no untested combinations of inputs", "correct": false }
      ],
      "explanation": "a) Is not correct. It is impossible to prove that there are no defects anymore in the system under test. See testing principle 1 <br>b) Is not correct. See testing principle 7 <br>c) Is correct. Testing finds defects and failures which reduces the level of risk and at the same time gives more confidence in the quality level of the test object <br>d) Is not correct. It is impossible to test all combinations of inputs (see testing principle 2) <br><br>FL-1.1.1 "
    },
    {
        "question": "Which of the following options shows an example of test activities that contribute to success?",
        "selectCount": 1,
        "options": [
          { "text": "a) Having testers involved during various software development lifecycle (SDLC) activities will help to detect defects in work products", "correct": true },
          { "text": "b) Testers try not to disturb the developers while coding, so that the developers write better code", "correct": false },
          { "text": "c) Testers collaborating with end users help to improve the quality of defect reports during component integration and system testing ", "correct": false },
          { "text": "d) Certified testers will design much better test cases than non-certified testers", "correct": false }
        ],
        "explanation": "a) Is correct. It is important that testers are involved from the beginning of the software development lifecycle (SDLC). It will increase understanding of design decisions and will detect defects early. <br>b) Is not correct. Both developers and testers will have more understanding of each other's work products and how to test the code <br>c) Is not correct. End users will not help the testers in increasing the quality of defect reports; also, users usually do not participate in low-level testing levels like integration testing <br>d) Is not correct. Being certified does not automatically mean that the tester will be better in test design <br><br>FL-1.2.1"
    },
    {
        "question": "You have been assigned as a tester to a team producing a new system incrementally. You have noticed that no changes have been made to the existing regression test cases for several iterations and no new regression defects were identified. Your manager is happy, but you are not. <br><br>Which testing principle explains your skepticism?",
        "selectCount": 1,
        "options": [
          { "text": "a) Tests wear out", "correct": true },
          { "text": "b) Absence-of-errors fallacy", "correct": false },
          { "text": "c) Defects cluster together", "correct": false },
          { "text": "d) Exhaustive testing is impossible", "correct": false }
        ],
        "explanation": "a) Is correct. This principle means that if the same tests are repeated over and over again, eventually these tests no longer find any new defects. This is probably why the tests all passed in this release as well <br>b) Is not correct. This principle says about the mistaken belief that just finding and fixing a large number of defects will ensure the success of a system <br>c) Is not correct. This principle says that a small number of components usually contain most of the defects <br>d) Is not correct. This principle states that testing all combinations of inputs and preconditions is not feasible <br><br>FL-1.3.1"
    },
    {
        "question": "You work in a team that develops a mobile application for food ordering. In the current iteration the team decided to implement the payment functionality. <br><br>Which of the following activities is a part of test analysis? ",
        "selectCount": 1,
        "options": [
          { "text": "a) Estimating that testing the integration with the payment service will take 8 person-days", "correct": false },
          { "text": "b) Deciding that the team should test if it is possible to properly share payment between many users", "correct": true },
          { "text": "c) Using boundary value analysis (BVA) to derive the test data for the test cases that check the correct payment processing for the minimum allowed amount to be paid", "correct": false },
          { "text": "d) Analyzing the discrepancy between the actual result and expected result after executing a test case that checks the process of payment with a credit card, and reporting a defect ", "correct": false }
        ],
        "explanation": "a) Is not correct. Estimating the test effort is part of test planning <br>b) Is correct. This is an example of defining test conditions which is a part of test analysis <br>c) Is not correct. Using test techniques to derive coverage items is a part of test design <br>d) Is not correct. Reporting defects found during dynamic testing is a part of test execution <br><br>FL-1.4.1 "
    },
    {
        "question": "Which of the following factors have a SIGNIFICANT influence on the test approach? <br>i. The SDLC <br>ii. The number of defects detected in previous projects <br>iii. The identified product risks <br>iv. New regulatory requirements forcing formal white-box testing <br>v. The test environment setup",
        "selectCount": 1,
        "options": [
          { "text": "a) i, ii have significant influence ", "correct": false },
          { "text": "b) i, iii, iv have significant influence ", "correct": true },
          { "text": "c) ii, iv, v have significant influence ", "correct": false },
          { "text": "d) iii, v have significant influence", "correct": false }
        ],
        "explanation": "i. Is true. The SDLC has an influence on the test approach <br>ii. Is false. The number of defects detected in previous projects may have some influence, but this is not as significant as i, iii and iv <br>iii. Is true. The identified product risks are one of the most important factors influencing the test approach <br>iv. Is true. Regulatory requirements are important factors influencing the test approach <br>v. Is false. The test environment has no significant influence on the test approach <br><br>Thus: <br>a) Is not correct <br>b) Is correct <br>c) Is not correct <br>d) Is not correct <br><br>FL-1.4.2"
    },
    {
        "question": "Which TWO of the following tasks belong MAINLY to a testing role?",
        "selectCount": 2,
        "options": [
          { "text": "a) Configure test environments ", "correct": true },
          { "text": "b) Maintain the product backlog ", "correct": false },
          { "text": "c) Design solutions to new requirements ", "correct": false },
          { "text": "d) Create the test plan ", "correct": false },
          { "text": "e) Analyze the test basis", "correct": true }
        ],
        "explanation": "a) Is correct. This is done by the testers <br>b) Is not correct. The product backlog is built and maintained by the product owner <br>c) Is not correct. This is done by the development team <br>d) Is not correct. This is a managerial role <br>e) Is correct. This is done by the testers since its technical task done as part of a test analysis.  <br><br>FL-1.4.5"
    },
    {
        "question": "Which of the following skills (i-v) are the MOST important skills of a tester?<br> <br>i. Having domain knowledge <br>ii. Creating a product vision <br>iii. Being a good team player <br>iv. Planning and organizing the work of the team <br>v. Critical thinking",
        "selectCount": 1,
        "options": [
          { "text": "a) ii and iv are important", "correct": false },
          { "text": "b) i, iii and v are important", "correct": true },
          { "text": "c) i, ii and v are important", "correct": false },
          { "text": "d) iii and iv are important", "correct": false }
        ],
        "explanation": "i. Is true. Having domain knowledge is an important tester skill <br>ii. Is false. This is a task of the business analyst together with the business representative <br>iii. Is true. Being a good team player is an important skill <br>iv. Is false. Planning and organizing the work of the team is a task of the test manager or, mostly in an Agile software development project, the whole team and not just the tester <br>v. Is true. Critical thinking is one of the most important skills of testers <br><br>Thus: <br>a) Is not correct <br>b) Is correct <br>c) Is not correct <br>d) Is not correct <br><br>FL-1.5.1"
    },
    {
        "question": "How is the whole team approach present in the interactions between testers and business representatives?",
        "selectCount": 1,
        "options": [
          { "text": "a) Business representatives decide on test automation approaches", "correct": false },
          { "text": "b) Testers help business representatives to define test strategy", "correct": false },
          { "text": "c) Business representatives are not part of the whole team approach", "correct": false },
          { "text": "d) Testers help business representatives to create suitable acceptance tests ", "correct": true }
        ],
        "explanation": "a) Is not correct. The test automation approach is defined by testers with the help of developers and business representatives <br>b) Is not correct. The test strategy is decided in collaboration with the developers <br>c) Is not correct. Testers, developers, and business representatives are part of the whole team approach <br>d) Is correct. Testers will work closely with business representatives to ensure that the desired quality levels are achieved. This includes supporting and collaborating with them to help them create suitable acceptance tests  <br><br>FL-1.5.2"
    },
    {
        "question": "Consider the following rule: “for every SDLC activity there is a corresponding test activity”. In which SDLC models does this rule hold?",
        "selectCount": 1,
        "options": [
          { "text": "a) Only in sequential SDLC models", "correct": false },
          { "text": "b) Only in iterative SDLC models", "correct": false },
          { "text": "c) Only in iterative and incremental SDLC models", "correct": false },
          { "text": "d) In sequential, incremental, and iterative SDLC models", "correct": true }
        ],
        "explanation": "a) Is not correct <br>b) Is not correct <br>c) Is not correct <br>d) Is correct. This rule holds for all SDLC models  <br><br>FL-2.1.2"
    },
    {
        "question": "Which of the following statements BEST describes the acceptance test-driven development (ATDD) approach?",
        "selectCount": 1,
        "options": [
          { "text": "a) In ATDD, acceptance criteria are typically created based on the given/when/then format", "correct": false },
          { "text": "b) In ATDD, test cases are mainly created at component testing and are code-oriented", "correct": false },
          { "text": "c) In ATDD, tests are created, based on acceptance criteria to drive the development of the related software", "correct": true },
          { "text": "d) in ATDD, tests are based on the desired behavior of the software, which makes it easier for team members to understand them", "correct": false }
        ],
        "explanation": "a) Is not correct. It is more often used in behavior-driven development (BDD) <br>b) Is not correct. It is the description of test-driven development (TDD) <br>c) Is correct. In acceptance test-driven development (ATDD) tests are written from acceptance criteria as part of the design process <br>d) Is not correct. It is used in BDD  <br><br>FL-2.1.3"
    },
    {
        "question": "Which of the following is NOT an example of the shift left approach?",
        "selectCount": 1,
        "options": [
          { "text": "a) Reviewing the user requirements before they are formally accepted by the stakeholders", "correct": false },
          { "text": "b) Writing a component test before the corresponding code is written", "correct": false },
          { "text": "c) Executing a performance efficiency test for a component during component testing", "correct": false },
          { "text": "d) Writing a test script before setting up the configuration management process", "correct": true }
        ],
        "explanation": "a) Is not correct. Early review is an example of the shift left approach <br>b) Is not correct. TDD is an example of the shift left approach <br>c) Is not correct. Early non-functional testing is an example of the shift left approach <br>d) Is correct. Test scripts should be subject to configuration management, so it makes no sense to create the test scripts before this process is set up  <br><br>FL-2.1.5"
    },
    {
        "question": "Which of the arguments below would you use to convince your manager to organize retrospectives at the end of each release cycle?",
        "selectCount": 1,
        "options": [
          { "text": "a) Retrospectives are very popular these days and clients would appreciate it if we added them to our processes", "correct": false },
          { "text": "b) Organizing retrospectives will save the organization money because without them end user representatives do not provide immediate feedback about the product", "correct": false },
          { "text": "c) Process weaknesses identified during the retrospective can be analyzed and serve as a to do list for the organization’s continuous process improvement program", "correct": true },
          { "text": "d) Retrospectives embrace five values including courage and respect, which are crucial to maintain continuous improvement in the organization", "correct": false }
        ],
        "explanation": "a) Is not correct. Retrospectives are more useful for identifying improvement opportunities and have little importance for clients <br>b) Is not correct. Retrospectives are not aimed to collect feedback about the product, but about the process. Additionally, retrospectives are internal activity for the team and should not include end user representatives <br>c) Is correct. Regularly conducted retrospectives, when appropriate follow up activities occur, are critical to continual improvement of development and testing <br>d) Is not correct. Courage and respect are values of Extreme Programming and are not closely related to retrospectives   <br><br>FL-2.1.6"
    },
    {
        "question": "Which types of failures (1-4) fit which test levels (A-D) BEST? <br>1. Failures in system behavior as it deviates from the user’s business needs <br>2. Failures in communication between components <br>3. Failures in logic in a module <br>4. Failures in not correctly implemented business rules<br><br> <br>A. Component testing <br>B. Component integration testing <br>C. System testing <br>D. Acceptance testing",
        "selectCount": 1,
        "options": [
          { "text": "a) 1D, 2B, 3A, 4C", "correct": true },
          { "text": "b) 1D, 2B, 3C, 4A", "correct": false },
          { "text": "c) 1B, 2A, 3D, 4C", "correct": false },
          { "text": "d) 1C, 2B, 3A, 4D", "correct": false }
        ],
        "explanation": "Considering: <br>- The test basis for acceptance testing is the user’s business needs (1D) <br>- Communication between components is tested during component integration testing (2B) <br>- Failures in logic can be found during component testing (3A) <br>- Business rules are the test basis for system testing (4C) <br><br>Thus: <br>a) Is correct <br>b) Is not correct <br>c) Is not correct <br>d) Is not correct <br><br>FL-2.2.1"
    },
    {
        "question": "You are testing a user story with three acceptance criteria: AC1, AC2 and AC3. AC1 is covered by test case TC1, AC2 by TC2, and AC3 by TC3. The test execution history had three test runs on three consecutive versions of the software as follows: <br> <img src=\"QAA/qA14.png\"> <br> Tests are repeated once you are informed that all defects found in the test run are corrected and a new version of the software is available. <br> Which of the above tests are executed as regression tests?",
        "selectCount": 1,
        "options": [
          { "text": "a) Only 4, 7, 8, 9", "correct": false },
          { "text": "b) Only 5, 7", "correct": true },
          { "text": "c) Only 4, 6, 8, 9", "correct": false },
          { "text": "d) Only 5, 6", "correct": false }
        ],
        "explanation": "Because TC1 and TC3 failed in Execution 1 (i.e., test (1) and test (3)), test (4) and test (6) are confirmation tests. <br>Because TC2 and TC3 failed in Execution 2 (i.e., tests (5) and (6)), test (8) and test (9) are also confirmation tests. <br>TC2 passed in Execution 1 (i.e., test (2)), so test (5) is a regression test. <br>TC1 passed in the Execution 2 (i.e., test (4)), so test (7) is also a regression test. <br>Thus: <br>a) Is not correct <br>b) Is correct <br>c) Is not correct <br>d) Is not correct  <br><br>FL-2.2.3"
    },
    {
        "question": "Which of the following is NOT a benefit of static testing?",
        "selectCount": 1,
        "options": [
          { "text": "a) Having less expensive defect management due to the ease of detecting defects later in the SDLC", "correct": true },
          { "text": "b) Fixing defects found during static testing is generally much less expensive than fixing defects found during dynamic testing", "correct": false },
          { "text": "c) Finding coding defects that might not have been found by only performing dynamic testing", "correct": false },
          { "text": "d) Detecting gaps and inconsistencies in requirements", "correct": false }
        ],
        "explanation": "a) Is correct. Defect management is no less expensive. Finding and fixing defects later in SDLC is more costly <br>b) Is not correct. This is a benefit of static testing <br>c) Is not correct. This is a benefit of static testing <br>d) Is not correct. This is a benefit of static testing  <br><br>FL-3.1.2"
    },
    {
        "question": "Which of the following is a benefit of early and frequent feedback?",
        "selectCount": 1,
        "options": [
          { "text": "a) It improves the test process for future projects", "correct": false },
          { "text": "b) It forces customers to prioritize their requirements based on agreed risks", "correct": false },
          { "text": "c) It provides a measure for the quality of changes", "correct": false },
          { "text": "d) It helps avoid requirements misunderstandings", "correct": true }
        ],
        "explanation": "a) Is not correct. Feedback can improve the test process, but if one only wants to improve future projects, the feedback does not need to come early or frequently <br>b) Is not correct. Feedback is not used to prioritize requirements <br>c) Is not correct. There is no one, recommended way to measure quality of changes. Also, this is not one of the benefits of early feedback that are mentioned in section 3.2.1 <br>d) Is correct. Early and frequent feedback can prevent misunderstandings about requirements <br><br>FL-3.2.1"
    },
    {
        "question": "The reviews being used in your organization have the following attributes: <br>- There is the role of a scribe <br>- The main purpose is to evaluate quality <br>- The meeting is led by the author of the work product <br>- There is individual preparation <br>- A review report is produced <br>Which of the following review types is MOST likely being used? ",
        "selectCount": 1,
        "options": [
          { "text": "a) Informal review ", "correct": false },
          { "text": "b) Walkthrough", "correct": true },
          { "text": "c) Technical review ", "correct": false },
          { "text": "d) Inspection", "correct": false }
        ],
        "explanation": "Considering the attributes: <br>- Specified for walkthroughs, technical reviews, and inspections; thus, the reviews being performed cannot be informal reviews <br>- The purpose of evaluating quality is one of the most important objectives of a walkthrough <br>- This is not allowed for inspections and is typically not done in technical reviews. A moderator is needed in walkthroughs and is allowed for informal reviews <br>- All types of reviews can include individual preparation (even informal reviews) <br>- All types of reviews can produce a review report, although informal reviews do not require documentation <br><br>Thus: <br>a) Is not correct <br>b) Is correct <br>c) Is not correct <br>d) Is not correct  <br><br>FL-3.2.4"
    },
    {
        "question": "Which of these statements is NOT a factor that contributes to successful reviews?",
        "selectCount": 1,
        "options": [
          { "text": "a) Participants should dedicate adequate time for the review", "correct": false },
          { "text": "b) Splitting large work products into small parts to make the required effort less intense", "correct": false },
          { "text": "c) Participants should avoid behaviors that might indicate boredom, exasperation, or hostility to other participants", "correct": false },
          { "text": "d) Failures found should be acknowledged, appreciated, and handled objectively", "correct": true }
        ],
        "explanation": "a) Is not correct. Adequate time for individuals is a success factor <br>b) Is not correct. Splitting work products into small adequate parts is a success factor <br>c) Is not correct. Avoiding behaviors that might indicate boredom, exasperation, etc. is a success factor <br>d) Is correct. During reviews one can find defects, not failures <br><br>FL-3.2.5"
    },
    {
        "question": "Which of the following is a characteristic of experience-based test techniques?",
        "selectCount": 1,
        "options": [
          { "text": "a) Test cases are created based on detailed design information", "correct": false },
          { "text": "b) Items tested within the interface code section are used to measure coverage", "correct": false },
          { "text": "c) The techniques heavily rely on the tester’s knowledge of the software and the business domain", "correct": true },
          { "text": "d) The test cases are used to identify deviations from the requirements", "correct": false }
        ],
        "explanation": "a) Is not correct. This is a common characteristic of white-box test techniques. Test conditions, test cases, and test data are derived from a test basis that may include code, software architecture, detailed design, or any other source of information regarding the structure of the software. <br>b) Is not correct. This is a common characteristic of white-box test techniques. Coverage is measured based on the items tested within a selected structure and the technique applied to the test basis <br>c) Is correct. This is a common characteristic of experience-based test techniques. This knowledge and experience include expected use of the software, its environment, likely defects, and the distribution of those defects is used to define tests <br>d) Is not correct. This is a common characteristic of black-box test techniques. Test cases may be used to detect gaps within requirements and the implementation of the requirements, as well as deviations from the requirements <br><br>FL-4.1.1"
    },
    {
        "question": "You are testing a simplified apartment search form which has only two search criteria: <br>- floor (with three possible options: ground floor; first floor; second or higher floor) <br>- garden type (with three possible options: no garden; small garden; large garden) <br>Only apartments on the ground floor have gardens. The form has a built-in validation mechanism that will not allow you to use the search criteria which violate this rule. <br>Each test has two input values: floor and garden type. You want to apply equivalence partitioning (EP) to cover each floor and each garden type in your tests. <br><br>What is the minimal number of test cases to achieve 100% EP coverage? ",
        "selectCount": 1,
        "options": [
          { "text": "a) 3", "correct": false },
          { "text": "b) 4", "correct": true },
          { "text": "c) 5", "correct": false },
          { "text": "d) 6", "correct": false }
        ],
        "explanation": "“Small garden” and “large garden” can go only with “ground floor”, so we need two test cases with “ground floor” which cover these two “garden type” partitions. <br>We need two more test cases to cover the two other “floor” partitions and a remaining ”garden type” partition of “no garden”. <br>We need a total of four test cases: <br>- TC1 (ground floor, small garden) <br>- TC2 (ground floor, large garden) <br>- TC3 (first floor, no garden) <br>- TC4 (second or higher floor, no garden) <br><br>Thus: <br>a) Is not correct <br>b) Is correct <br>c) Is not correct <br>d) Is not correct <br><br>FL-4.2.1"
    },
    {
        "question": "You are testing a system that calculates the final course grade for a given student. <br>The final grade is assigned based on the final result, according to the following rules: <br>- 0 – 50 points: failed <br>- 51 – 60 points: fair <br>- 61 – 70 points: satisfactory <br>- 71 – 80 points: good <br>- 81 – 90 points: very good <br>- 91 – 100 points: excellent <br>You have prepared the following set of test cases: <br> <img src=\"QAA/qA21.png\"> <br>What is the 2-value Boundary Value Analysis (BVA) coverage for the final result that is achieved with the existing test cases?",
        "selectCount": 1,
        "options": [
          { "text": "a) 50%", "correct": true },
          { "text": "b) 60%", "correct": false },
          { "text": "c) 33.3%", "correct": false },
          { "text": "d) 100%", "correct": false }
        ],
        "explanation": "There are 12 boundary values for the final result values: 0, 50, 51, 60, 61, 70, 71, 80, 81, 90, 91, and 100. <br>The test cases cover six of them (TC1 – 91, TC2 – 50, TC3 – 81, TC4 – 60, TC5 – 70 and TC7 – 51). <br>Therefore, the test cases cover 6/12 = 50%. <br><br>Thus: <br>a) Is correct <br>b) Is not correct <br>c) Is not correct <br>d) Is not correct <br><br>FL-4.2.2"
    },
    {
        "question": "Your favorite bicycle daily rental store has just introduced a new Customer Relationship <br>Management system and asked you, one of their most loyal members, to test it. <br>The implemented features are as follows: <br>- Anyone can rent a bicycle, but members receive a 20% discount <br>- However, if the return deadline is missed, the discount is no longer available <br>- After 15 rentals, members get a gift: a T-Shirt <br>Decision table describing the implemented features looks as follows: <br> <img src=\"QAA/qA22.png\"> <br> Based ONLY on the feature description of the Customer Relationship Management system, which of the above rules describes an impossible situation?",
        "selectCount": 1,
        "options": [
          { "text": "a) R4", "correct": false },
          { "text": "b) R2", "correct": false },
          { "text": "c) R6", "correct": false },
          { "text": "d) R8", "correct": true }
        ],
        "explanation": "a) Is not correct. A member without a missed deadline can get a discount and a gift T-Shirt after 15 bicycle rentals <br>b) Is not correct. A member without a missed deadline can get a discount but no gift T-Shirt until they rented a bicycle 15 times <br>c) Is not correct. Non-members cannot get a discount, even if they did not miss a deadline yet <br>d) Is correct. No discount as a non-member that has also missed a deadline, but only members can receive a gift T-Shirt. Hence, the action is not correct <br><br>FL-4.2.3"
    },
    {
        "question": "You test a system whose lifecycle is modeled by the state transition diagram shown below. The system starts in the INIT state and ends its operation in the OFF state. <br> <img src=\"QAA/qA23.png\"> <br>What is the MINIMAL number of test cases to achieve valid transitions coverage? ",
        "selectCount": 1,
        "options": [
          { "text": "a) 4", "correct": false },
          { "text": "b) 2", "correct": false },
          { "text": "c) 7", "correct": false },
          { "text": "d) 3", "correct": true }
        ],
        "explanation": "“test” and “error” transitions cannot occur in one test case. <br>Neither can both “done” transitions. This means we need at least three test cases to achieve transition coverage. For example: <br>TC1: test, done <br>TC2: run, error, done <br>TC3: run, pause, resume, pause, done <br>Thus: <br>a) Is not correct <br>b) Is not correct <br>c) Is not correct <br>d) Is correct<br><br>FL-4.2.4"
    },
    {
        "question": "Your test suite achieved 100% statement coverage. What is the consequence of this fact? ",
        "selectCount": 1,
        "options": [
          { "text": "a) Each instruction in the code that contains a defect has been executed at least once", "correct": true },
          { "text": "b) Any test suite containing more test cases than your test suite will also achieve 100% statement coverage", "correct": false },
          { "text": "c) Each path in the code has been executed at least once", "correct": false },
          { "text": "d) Every combination of input values has been tested at least once", "correct": false }
        ],
        "explanation": "a) Is correct. Since 100% statement coverage is achieved, every statement, including the ones with defects, must have been executed and evaluated at least once <br>b) Is not correct. Coverage depends on what is tested, not on the number of test cases. For example, for code “if (x==0) y=1”, one test case (x=0) achieves 100% statement coverage, but two test cases (x=1) and (x=2) together achieve only 50% statement coverage <br>c) Is not correct. If there is a loop in the code there may be an infinite number of possible paths, so it is not possible to execute all the possible paths in the code <br>d) Is not correct. Exhaustive testing is not possible (see the seven testing principles section in the syllabus). For example, for code “input x; print x” any single test with arbitrary x achieves 100% statement coverage, but covers one input value<br><br>FL-4.3.1"
    },
    {
        "question": "Which of the following is NOT true for white-box testing? ",
        "selectCount": 1,
        "options": [
          { "text": "a) During white-box testing the entire software implementation is considered", "correct": false },
          { "text": "b) White-box coverage metrics can help identify additional tests to increase code coverage", "correct": false },
          { "text": "c) White-box test techniques can be used in static testing", "correct": false },
          { "text": "d) White-box testing can help identify gaps in requirements implementation", "correct": true }
        ],
        "explanation": "a) Is not correct. The fundamental strength of white-box test techniques is that the entire software implementation is taken into account during testing <br>b) Is not correct. White-box coverage measures provide an objective measure of coverage and provide the necessary information to allow additional tests to be generated to increase this coverage <br>c) Is not correct. White-box test techniques can be used to perform reviews (static testing) <br>d) Is correct. This is the weakness of the white-box test techniques. They are not able to identify the missing implementation, because they are based solely on the test object structure, not on the requirements specification <br><br>FL-4.3.3"
    },
    {
        "question": "Which of the following BEST describes the concept behind error guessing? ",
        "selectCount": 1,
        "options": [
          { "text": "a) Error guessing involves using your knowledge and experience of defects found in the past and typical errors made by developers", "correct": true },
          { "text": "b) Error guessing involves using your personal experience of development and the errors you made as a developer", "correct": false },
          { "text": "c) Error guessing requires you to imagine that you are the user of the test object and to guess errors the user could make interacting with it", "correct": false },
          { "text": "d) Error guessing requires you to rapidly duplicate the development task to identify the sort of errors a developer might make ", "correct": false }
        ],
        "explanation": "a) Is correct. The basic concept behind error guessing is that the tester tries to guess what errors may have been made by the developer and what defects may be in the test object based on past experience (and sometimes checklists) <br>b) Is not correct. Although a testers who used to be a developer may use their personal experience to help them when performing error guessing, the test technique is not based on prior knowledge of development <br>c) Is not correct. Error guessing is not a usability technique for guessing how users may fail to interact with the test object <br>d) Is not correct. Duplicating the development task has several flaws that make it impractical, such as the tester having equivalent skills to the developer and the time involved to perform the development. It is not error guessing <br><br>FL-4.4.1"
    },
    {
        "question": "In your project there has been a delay in the release of a brand-new application and test execution started late, but you have very detailed domain knowledge and good analytical skills. The full list of requirements has not yet been shared with the team, but management is asking for some test results to be presented. <br><br>Which test technique fits BEST in this situation?",
        "selectCount": 1,
        "options": [
          { "text": "a) Checklist-based testing", "correct": false },
          { "text": "b) Error guessing", "correct": false },
          { "text": "c) Exploratory testing", "correct": true },
          { "text": "d) Branch testing", "correct": false }
        ],
        "explanation": "a) Is not correct. This is a new product. You probably do not have a checklist yet and test conditions might not be known due to missing requirements <br>b) Is not correct. This is a new product. You probably do not have enough information to make correct error guesses <br>c) Is correct. Exploratory testing is most useful when there are few known specifications and/or there is a pressing timeline for testing <br>d) Is not correct. Branch testing is time-consuming, and your management is asking about some test results now. Also, branch testing does not involve domain knowledge <br><br>FL-4.4.2"
    },
    {
        "question": "Which of the following BEST describes the way acceptance criteria can be documented?",
        "selectCount": 1,
        "options": [
          { "text": "a) Performing retrospectives to determine the actual needs of the stakeholders regarding a given user story", "correct": false },
          { "text": "b) Using the given/when/then format to describe an example test condition related to a given user story", "correct": true },
          { "text": "c) Using verbal communication to reduce the risk of misunderstanding the acceptance criteria by others", "correct": false },
          { "text": "d) Documenting risks related to a given user story in a test plan to facilitate the risk-based testing of a given user story", "correct": false }
        ],
        "explanation": "a) Is not correct. Retrospectives are used to capture lessons learned and to improve the development and testing process, not to document the acceptance criteria <br>b) Is correct. This is the standard way to document acceptance criteria <br>c) Is not correct. Verbal communication does not allow to physically document the acceptance criteria as part of a user story (”card” aspect in the 3C’s model) <br>d) Is not correct. Acceptance criteria are related to a user story, not a test plan. Also, acceptance criteria are the conditions that have to be fulfilled to decide if the user story is complete. Risks are not such conditions <br><br>FL-4.5.2"
    },
    {
        "question": "Consider the following user story: <br><br><i>As an Editor <br>I want to review content before it is published <br>so that I can assure the grammar is correct</i><br><br>and its acceptance criteria: <br>- The user can log in to the content management system with \"Editor\" role <br>- The editor can view existing content pages <br>- The editor can edit the page content <br>- The editor can add markup comments <br>- The editor can save changes <br>- The editor can reassign to the  \"content owner\" role to make updates <br>Which of the following is the BEST example of an ATDD test for this user story? ",
        "selectCount": 1,
        "options": [
          { "text": "a) Test if the editor can save the document after edit the page content", "correct": true },
          { "text": "b) Test if the content owner can log in and make updates to the content", "correct": false },
          { "text": "c) Test if the editor can schedule the edited content for publication", "correct": false },
          { "text": "d) Test if the editor can reassign to another editor to make updates", "correct": false }
        ],
        "explanation": "a) Is correct. This test covers two acceptance criteria: one about editing the document and one about saving changes <br>b) Is not correct. Acceptance criteria cover the editor activities, not the content owner activities <br>c) Is not correct. Scheduling the edited content for publication may be a nice feature, but it is not covered by the acceptance criteria <br>d) Is not correct. Acceptance criteria state about reassigning from an editor to the content owner, not to another editor <br><br>FL-4.5.3"
    },
    {
        "question": "How do testers add value to iteration and release planning?",
        "selectCount": 1,
        "options": [
          { "text": "a) Testers determine the priority of the user stories to be developed", "correct": false },
          { "text": "b) Testers focus only on the functional aspects of the system to be tested", "correct": false },
          { "text": "c) Testers participate in the detailed risk identification and risk assessment of user stories", "correct": true },
          { "text": "d) Testers guarantee the release of high-quality software through early test design during the release planning", "correct": false }
        ],
        "explanation": "a) Is not correct. Priorities for user stories are determined by the business representative together with the development team <br>b) Is not correct. Testers focus on both functional and non-functional aspects of the system to be tested <br>c) Is correct. According to the syllabus, this is one of the ways testers add value to iteration and release planning <br>d) Is not correct. Early test design is not part of release planning. Early test design does not automatically guarantee the release of quality software <br><br>FL-5.1.2"
    },
    {
        "question": "Which TWO of the following options are the exit criteria for testing a system?",
        "selectCount": 2,
        "options": [
          { "text": "a) Test environment readiness", "correct": false },
          { "text": "b) The ability to log in to the test object by the tester", "correct": false },
          { "text": "c) Estimated defect density is reached ", "correct": true },
          { "text": "d) Requirements are translated into given/when/then format", "correct": false },
          { "text": "e) Regression tests are automated", "correct": true }
        ],
        "explanation": "a) Is not correct. Test environment readiness is a resource availability criterion; hence it belongs to the entry criteria <br>b) Is not correct. This is a resource availability criterion; hence it belongs to the entry criteria <br>c) Is correct. Estimated defect density is a measure of diligence; hence it belongs to the exit criteria. <br>d) Is not correct. Requirements translated into a given format result in testable requirements; hence it belongs to the entry criteria <br>e) Is correct. Automation of regression tests is a completion criterion; hence it belongs to the exit criteria <br><br>FL-5.1.3"
    },
    {
        "question": "Your team uses the three-point estimation technique to estimate the test effort for a new high-risk feature. The following estimates were made: <br>- Most optimistic estimation: 2 person-hours <br>- Most likely estimation: 11 person-hours <br>- Most pessimistic estimation: 14 person-hours <br>What is the final estimate?",
        "selectCount": 1,
        "options": [
          { "text": "a) 9 person-hours ", "correct": false },
          { "text": "b) 14 person-hours", "correct": false },
          { "text": "c) 11 person-hours ", "correct": false },
          { "text": "d) 10 person-hours ", "correct": true }
        ],
        "explanation": "In the three-point estimation technique: <br>E = (optimistic + 4*most likely + pessimistic)/6 <br>E = (2+(4*11)+14)/6 = 10 <br><br>Thus: <br>a) Is not correct <br>b) Is not correct <br>c) Is not correct <br>d) Is correct <br><br>FL-5.1.3"
    },
    {
        "question": "You are testing a mobile application that allows users to find a nearby restaurant based on the type of food they want to eat. Consider the following list of test cases, priorities (i.e., a smaller number means a higher priority), and dependencies: <br> <img src=\"QAA/qA33.png\"> <br><br>Which of the following test cases should be executed as the third one?",
        "selectCount": 1,
        "options": [
          { "text": "a) TC 003", "correct": true },
          { "text": "b) TC 005", "correct": false },
          { "text": "c) TC 002", "correct": false },
          { "text": "d) TC 001", "correct": false }
        ],
        "explanation": "Test TC 001 must come first, followed by TC 002, to satisfy dependencies. <br>Afterwards, TC 003 to satisfy priority and then TC 004, followed by TC 005. <br><br>Thus: <br>a) Is correct <br>b) Is not correct <br>c) Is not correct <br>d) Is not correct<br><br>FL-5.1.5"
    },
    {
        "question": "Consider the following test categories (1-4) and agile testing quadrants (A-D): <br><br>1. Usability testing <br>2. Component testing <br>3. Functional testing <br>4. Reliability testing <br><br>A. Agile testing quadrant Q1: technology facing, supporting the development team <br>B. Agile testing quadrant Q2: business facing, supporting the development team <br>C. Agile testing quadrant Q3: business facing, critique the product <br>D. Agile testing quadrant Q4: technology facing, critique the product <br><br>How do the following test categories map onto the agile testing quadrants? ",
        "selectCount": 1,
        "options": [
          { "text": "a) 1C, 2A, 3B, 4D", "correct": true },
          { "text": "b) 1D, 2A, 3C, 4B ", "correct": false },
          { "text": "c) 1C, 2B, 3D, 4A", "correct": false },
          { "text": "d) 1D, 2B, 3C, 4A", "correct": false }
        ],
        "explanation": "Considering: <br>- Usability testing is in Q3 (1 – C) <br>- Component testing is in Q1 (2 – A) <br>- Functional testing is in Q2 (3 – B) <br>- Reliability testing is in Q4 (4 – D) <br><br>Thus: <br>a) Is correct <br>b) Is not correct <br>c) Is not correct <br>d) Is not correct <br><br>FL-5.1.7"
    },
    {
        "question": "During a risk analysis the following risk was identified and assessed: <br>- Risk: Response time is too long to generate a report <br>- Risk likelihood: medium; risk impact: high <br>- Response to risk: <br>&emsp;o An independent test team performs performance testing during system testing <br>&emsp;o A selected sample of end users performs alpha and beta acceptance testing before the release <br>What measure is proposed to be taken in response to this analyzed risk? ",
        "selectCount": 1,
        "options": [
          { "text": "a) Risk acceptance ", "correct": false },
          { "text": "b) Contingency plan", "correct": false },
          { "text": "c) Risk mitigation ", "correct": true },
          { "text": "d) Risk transfer ", "correct": false }
        ],
        "explanation": "a) Is not correct. We do not accept the risk; concrete actions are proposed <br>b) Is not correct. No contingency plans are proposed <br>c) Is correct. The proposed actions are related to testing, which is a form of risk mitigation <br>d) Is not correct. Risk is not transferred but mitigated<br><br>FL-5.2.4"
    },
    {
        "question": "Which work product can be used by an agile team to show the amount of work that has been completed and the amount of total work remaining for a given iteration?",
        "selectCount": 1,
        "options": [
          { "text": "a) Acceptance criteria ", "correct": false },
          { "text": "b) Defect report", "correct": false },
          { "text": "c) Test completion report ", "correct": false },
          { "text": "d) Burndown chart", "correct": true }
        ],
        "explanation": "a) Is not correct. Acceptance criteria are the conditions used to decide whether the user story is ready. They cannot show work progress <br>b) Is not correct. Defect reports inform about the defects. They do not show work progress <br>c) Is not correct. Test completion report can be created after the iteration is finished, so it will not show the progress continuously within an iteration <br>d) Is correct. Burndown charts are a graphical representation of work left to do versus time remaining. They are updated daily, so they can continuously show the work progress <br><br>FL-5.3.3 "
    },
    {
        "question": "You need to update one of the automated test scripts to be in line with a new requirement. Which process indicates that you create a new version of the test script in the test repository?",
        "selectCount": 1,
        "options": [
          { "text": "a) Traceability management", "correct": false },
          { "text": "b) Maintenance testing", "correct": false },
          { "text": "c) Configuration management ", "correct": true },
          { "text": "d) Requirements engineering", "correct": false }
        ],
        "explanation": "a) Is not correct. Traceability is the relationship between two or more work products, not between different versions of the same work product <br>b) Is not correct. Maintenance testing is about testing changes; it is not related closely to versioning <br>c) Is correct. To support testing, configuration management may involve the version control of all test items <br>d) Is not correct. Requirements engineering is the elicitation, documentation, and management of requirements; it is not closely related to test script versioning <br><br>FL-5.4.1 "
    },
    {
        "question": "You received the following defect report from the developers stating that the anomaly described in this test report is not reproducible.<br> <i>Application hangs up <br>2022-May-03 – John Doe – Rejected <br>The application hangs up after entering “Test input: $ä” in the Name field on the new user creation screen. Tried to log off, log in with test_admin01 account, same issue. Tried with other test admin accounts, same issue. No error message received; log (see attached) contains fatal error notification. Based on the test case TC-1305, the application should accept the provided input and create the user. Please fix with high priority, this feature is related to REQ-0012, which is a critical new business requirement.</i><br><br>What critical information is MISSING from this test report that would have been useful for the developers? ",
        "selectCount": 1,
        "options": [
          { "text": "a) Expected result and actual result", "correct": false },
          { "text": "b) References and defect status", "correct": false },
          { "text": "c) Test environment and test item", "correct": true },
          { "text": "d) Priority and severity", "correct": false }
        ],
        "explanation": "a) Is not correct. The expected result is “the application should accept the provided input and create the user”. The actual result is “The application hangs up after entering “Test input. $ä””. <br>b) Is not correct. There is a reference to the test case and to the related requirement and it states that the defect is rejected. Also, the defect status would not be very helpful for the developers <br>c) Is correct. We do not know in which test environment the anomaly was detected, and we also do not know which application (and its version) is affected <br>d) Is not correct. The defect report states that the anomaly is urgent, that it is a global issue (i.e., many, if not all, test administration accounts are affected) and states the impact is high for business stakeholders <br><br>FL-5.5.1"
    },
    {
        "question": "Which test activity does a data preparation tool support?",
        "selectCount": 1,
        "options": [
          { "text": "a) Test monitoring and control ", "correct": false },
          { "text": "b) Test analysis", "correct": false },
          { "text": "c) Test design and implementation ", "correct": true },
          { "text": "d) Test completion", "correct": false }
        ],
        "explanation": "a) Is not correct. Test monitoring involves the ongoing checking of all activities and comparison of actual progress against the test plan. Test control involves taking the actions necessary to meet the test objectives of the test plan. No test data are prepared during these activities. <br>b) Is not correct. Test analysis includes analysis of the test basis to identify test conditions and prioritize them. Test data are not prepared during this activity. <br>c) Is correct. Test design and implementation can both include the identification, creation or acquisition of the testware necessary for test execution (e.g., test data). <br>d) Is not correct. Test completion activities occur at project milestones (e.g., release, end of iteration, test level completion), so it is too late for preparing test data. <br><br>FL-6.1.1"
    },
    {
        "question": "Which item correctly identifies a potential risk of performing test automation?",
        "selectCount": 1,
        "options": [
          { "text": "a) It may introduce unknown regressions in production", "correct": false },
          { "text": "b) Sufficient efforts to maintain testware may not be properly allocated", "correct": true },
          { "text": "c) Testing tools and associated testware may not be sufficiently relied upon", "correct": false },
          { "text": "d) It may reduce the time allocated for manual testing ", "correct": false }
        ],
        "explanation": "a) Is not correct. Test automation does not introduce unknown regressions in production <br>b) Is correct. Wrong allocation of effort to maintain testware is a risk <br>c) Is not correct. Test tools must be selected so that they and their testware can be relied upon <br>d) Is not correct. The primary goal of test automation is to reduce manual testing. So, this is a benefit, not a risk <br><br>FL-6.2.1 "
    }
]